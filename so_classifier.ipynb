{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#StackOverflow answer classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from html.parser import HTMLParser\n",
    "from time import time\n",
    "from xml.etree import ElementTree as etree\n",
    "from xml.etree.ElementTree import Element\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qas_df = pd.read_csv('data/qas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###a) Textual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = ['text', 'accepted']\n",
    "text_qa_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "text_qa_df['accepted'] = qas_df['accepted']\n",
    "text_qa_df['text'] = qas_df.apply(lambda x: x['text'].replace('\\n', ''), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27233"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_qa_df[text_qa_df.accepted==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45614"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_qa_df[text_qa_df.accepted==False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>accepted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nvd3.js How to make a historical multiBarChart...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sphinx complex queries with mix of AND/OR - I'...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google App Scripts get IP - How can I restrict...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to use a different email with MailApp in G...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How to use a different email with MailApp in G...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text accepted\n",
       "0  nvd3.js How to make a historical multiBarChart...    False\n",
       "1  Sphinx complex queries with mix of AND/OR - I'...    False\n",
       "2  Google App Scripts get IP - How can I restrict...    False\n",
       "3  How to use a different email with MailApp in G...    False\n",
       "4  How to use a different email with MailApp in G...    False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_qa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_qa_df = text_qa_df.reindex(np.random.permutation(text_qa_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>accepted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9028</th>\n",
       "      <td>Get selected picker view component string valu...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>Error with running Python executable from scri...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49173</th>\n",
       "      <td>ActionBar coloring lost on nested preference s...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14310</th>\n",
       "      <td>Adding menu button to ActionBar Tab - I'm tryi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53547</th>\n",
       "      <td>NSAttributedString with dynamic ranges - I hav...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text accepted\n",
       "9028   Get selected picker view component string valu...    False\n",
       "14994  Error with running Python executable from scri...     True\n",
       "49173  ActionBar coloring lost on nested preference s...     True\n",
       "14310  Adding menu button to ActionBar Tab - I'm tryi...    False\n",
       "53547  NSAttributedString with dynamic ranges - I hav...    False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_qa_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, Perceptron, RidgeClassifier, SGDClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.utils.extmath import density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# categories = [\n",
    "#     'pos',\n",
    "#     'neg',\n",
    "# ]\n",
    "# print(\"Loading sentences for categories:\")\n",
    "# print(categories)\n",
    "# data_train, data_test = train_test_split(document_df, train_size=0.9, test_size=0.1, random_state=100)\n",
    "# print('Data loaded:')\n",
    "# print('Train set: {} samples'.format(len(data_train)))\n",
    "# print('Test set: {} samples'.format(len(data_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 1, 5, 4, 2, 0, 3, 9, 8], [7], [0, 0, 0, 1, 0, 0, 0, 1, 0], [0]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split([0,1,2,3,4,5,6,7,8,9], [0,0,0,0,1,0,0,0,0,1], train_size=0.9, test_size=0.1, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = text_qa_df['text']\n",
    "y = text_qa_df['accepted']\n",
    "X_data, X_val, y_data, y_val = train_test_split(X, y, train_size=0.9, test_size=0.1, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_data = X_data.reset_index(drop=True)\n",
    "X_val = X_val.reset_index(drop=True)\n",
    "y_data = y_data.reset_index(drop=True)\n",
    "y_val = y_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7285"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Adding custom delete button for table view wit...\n",
       "1    A static const variable declared and defined i...\n",
       "2    Reading and writing java.util.Date from Parcel...\n",
       "3    EF Query Not Applying Where Clause as Expected...\n",
       "4    content negotiation - displaying images in fir...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72847"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_qa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    45614\n",
       "True     27233\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'score_q', 'view_count', 'answer_count',\n",
       "       'comment_count_q', 'code_line_count_q', 'reputation_q',\n",
       "       'comment_count_a', 'code_line_count_a', 'score_a', 'accepted',\n",
       "       'reputation_a', 'id', 'text', 'percent_answered_questions_q',\n",
       "       'percent_accepted_answers_a'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qas_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_test['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_labels = np.array(map(lambda x: 1 if x == 'pos' else 0, data_train['sentiment']))\n",
    "# train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_labels = np.array(map(lambda x: 1 if x == 'pos' else 0, data_test['sentiment']))\n",
    "# test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def size_mb(docs):\n",
    "    return sum(len(s) for s in docs) / 1e6\n",
    "\n",
    "# data_train_size_mb = size_mb(data_train['sentence'])\n",
    "# data_test_size_mb = size_mb(data_test['sentence'])\n",
    "\n",
    "# print(\"%d documents - %0.3fMB (training set)\" % (\n",
    "#     len(data_train), data_train_size_mb))\n",
    "# print(\"%d documents - %0.3fMB (test set)\" % (\n",
    "#     len(data_test), data_test_size_mb))\n",
    "# print(\"%d categories\" % len(categories))\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 1]\n",
      " [2 5]]\n"
     ]
    }
   ],
   "source": [
    ">>> from sklearn.metrics import confusion_matrix\n",
    ">>> y_true = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1]\n",
    ">>> y_pred = [1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1]\n",
    ">>> print(confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 1]\n",
      " [2 5]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def benchmark(clf, X_train, X_test, y_train, y_test, name):\n",
    "    print(\"_\" * 80)\n",
    "    print(\"Training: %s\" % name)\n",
    "    print(clf)\n",
    "    \n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    precision = metrics.precision_score(y_test, pred)\n",
    "    print(\"precision:   %0.3f\" % score)\n",
    "\n",
    "    recall = metrics.recall_score(y_test, pred)\n",
    "    print(\"recall:   %0.3f\" % score)\n",
    "\n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred, target_names=['No', 'Yes']))\n",
    "\n",
    "    print(\"confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    return score, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "K = 10\n",
    "parameters = {\n",
    "#     'vect__max_df': (0.5, 0.75, 1.0),\n",
    "#     'vect__max_features': (None, 1000, 5000, 10000, 50000),\n",
    "#     'vect__ngram_range': ((1, 1), (1, 2), (2, 2), (1, 3), (2, 3), (3, 3)),  # unigrams or bigrams or trigrams\n",
    "    'vect__stop_words': (None, stopwords.words('english')),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "#     'tfidf__norm': ('l1', 'l2'),\n",
    "#     'clf__alpha': (1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6),\n",
    "#     'clf__penalty': ('l1', 'l2', 'elasticnet'),\n",
    "#     'clf__n_iter': (10, 50, 80),\n",
    "#     'clf__loss': ('log', 'modified_huber'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Classifiers\n",
    "clf_list = [\n",
    "    (RidgeClassifier(alpha=.00001, tol=1e-2, solver=\"lsqr\"), \"Ridge classifier\"),\n",
    "    (Perceptron(alpha=.00001, n_iter=50), \"Perceptron\"),\n",
    "    (PassiveAggressiveClassifier(n_iter=50), \"Passive-aggressive\"),\n",
    "#     NO USAR (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "#     MUY LENTO (RandomForestClassifier(n_estimators=100), \"Random forest\"),\n",
    "    (LinearSVC(loss='squared_hinge', penalty='l2', dual=False, tol=1e-3), 'Linear SVC'),\n",
    "    (SGDClassifier(alpha=.000001, n_iter=50, penalty='l1'), 'SGDClassifier'),\n",
    "    (NearestCentroid(), 'Nearest Centroid'),\n",
    "    (MultinomialNB(alpha=.00001), 'Multinomial NB'),\n",
    "    (BernoulliNB(alpha=.00001), 'Bernoulli NB'),\n",
    "    (LinearSVC(penalty=\"l1\", dual=False, tol=1e-3), 'Linear SVC'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: Ridge classifier\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...True,\n",
      "        fit_intercept=True, max_iter=None, normalize=False, solver='lsqr',\n",
      "        tol=0.01))])\n",
      "train time: 16.758s\n",
      "test time:  8.114s\n",
      "accuracy:   0.550\n",
      "precision:   0.550\n",
      "recall:   0.550\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.63      0.67      0.65     20516\n",
      "        Yes       0.39      0.35      0.37     12265\n",
      "\n",
      "avg / total       0.54      0.55      0.54     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[13772  6744]\n",
      " [ 8021  4244]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Perceptron\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ..._iter=50, n_jobs=1, penalty=None, random_state=0, shuffle=True,\n",
      "      verbose=0, warm_start=False))])\n",
      "train time: 16.726s\n",
      "test time:  7.781s\n",
      "accuracy:   0.547\n",
      "precision:   0.547\n",
      "recall:   0.547\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.63      0.68      0.65     20516\n",
      "        Yes       0.38      0.32      0.35     12265\n",
      "\n",
      "avg / total       0.53      0.55      0.54     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[13993  6523]\n",
      " [ 8334  3931]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Passive-aggressive\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...  n_iter=50, n_jobs=1, random_state=None, shuffle=True,\n",
      "              verbose=0, warm_start=False))])\n",
      "train time: 17.103s\n",
      "test time:  7.956s\n",
      "accuracy:   0.543\n",
      "precision:   0.543\n",
      "recall:   0.543\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.63      0.65      0.64     20516\n",
      "        Yes       0.38      0.36      0.37     12265\n",
      "\n",
      "avg / total       0.54      0.54      0.54     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[13347  7169]\n",
      " [ 7823  4442]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Linear SVC\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
      "     verbose=0))])\n",
      "train time: 23.836s\n",
      "test time:  8.110s\n",
      "accuracy:   0.574\n",
      "precision:   0.574\n",
      "recall:   0.574\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.64      0.75      0.69     20516\n",
      "        Yes       0.40      0.28      0.33     12265\n",
      "\n",
      "avg / total       0.55      0.57      0.55     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[15419  5097]\n",
      " [ 8858  3407]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: SGDClassifier\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...   penalty='l1', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False))])\n",
      "train time: 20.165s\n",
      "test time:  7.689s\n",
      "accuracy:   0.548\n",
      "precision:   0.548\n",
      "recall:   0.548\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.63      0.66      0.65     20516\n",
      "        Yes       0.39      0.36      0.37     12265\n",
      "\n",
      "avg / total       0.54      0.55      0.54     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[13521  6995]\n",
      " [ 7821  4444]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Nearest Centroid\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...alse,\n",
      "         use_idf=False)), ('clf', NearestCentroid(metric='euclidean', shrink_threshold=None))])\n",
      "train time: 15.124s\n",
      "test time:  7.836s\n",
      "accuracy:   0.550\n",
      "precision:   0.550\n",
      "recall:   0.550\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.68      0.53      0.60     20516\n",
      "        Yes       0.43      0.58      0.49     12265\n",
      "\n",
      "avg / total       0.58      0.55      0.56     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[10903  9613]\n",
      " [ 5138  7127]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Multinomial NB\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...se,\n",
      "         use_idf=False)), ('clf', MultinomialNB(alpha=1e-05, class_prior=None, fit_prior=True))])\n",
      "train time: 15.931s\n",
      "test time:  7.913s\n",
      "accuracy:   0.537\n",
      "precision:   0.537\n",
      "recall:   0.537\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.61      0.74      0.67     20516\n",
      "        Yes       0.31      0.20      0.24     12265\n",
      "\n",
      "avg / total       0.50      0.54      0.51     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[15190  5326]\n",
      " [ 9866  2399]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Bernoulli NB\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ... use_idf=False)), ('clf', BernoulliNB(alpha=1e-05, binarize=0.0, class_prior=None, fit_prior=True))])\n",
      "train time: 14.929s\n",
      "test time:  7.955s\n",
      "accuracy:   0.537\n",
      "precision:   0.537\n",
      "recall:   0.537\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.61      0.74      0.67     20516\n",
      "        Yes       0.31      0.19      0.24     12265\n",
      "\n",
      "avg / total       0.50      0.54      0.51     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[15255  5261]\n",
      " [ 9905  2360]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Linear SVC\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0))])\n",
      "train time: 19.228s\n",
      "test time:  8.697s\n",
      "accuracy:   0.598\n",
      "precision:   0.598\n",
      "recall:   0.598\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.65      0.79      0.71     20516\n",
      "        Yes       0.44      0.28      0.35     12265\n",
      "\n",
      "avg / total       0.57      0.60      0.57     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[16110  4406]\n",
      " [ 8780  3485]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Ridge classifier\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...True,\n",
      "        fit_intercept=True, max_iter=None, normalize=False, solver='lsqr',\n",
      "        tol=0.01))])\n",
      "train time: 18.268s\n",
      "test time:  7.966s\n",
      "accuracy:   0.545\n",
      "precision:   0.545\n",
      "recall:   0.545\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.63      0.66      0.65     20516\n",
      "        Yes       0.38      0.35      0.36     12265\n",
      "\n",
      "avg / total       0.54      0.55      0.54     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[13621  6895]\n",
      " [ 8010  4255]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Perceptron\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ..._iter=50, n_jobs=1, penalty=None, random_state=0, shuffle=True,\n",
      "      verbose=0, warm_start=False))])\n",
      "train time: 17.986s\n",
      "test time:  7.923s\n",
      "accuracy:   0.548\n",
      "precision:   0.548\n",
      "recall:   0.548\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.63      0.67      0.65     20516\n",
      "        Yes       0.38      0.35      0.37     12265\n",
      "\n",
      "avg / total       0.54      0.55      0.54     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[13694  6822]\n",
      " [ 7998  4267]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Passive-aggressive\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...  n_iter=50, n_jobs=1, random_state=None, shuffle=True,\n",
      "              verbose=0, warm_start=False))])\n",
      "train time: 17.493s\n",
      "test time:  7.732s\n",
      "accuracy:   0.549\n",
      "precision:   0.549\n",
      "recall:   0.549\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.63      0.68      0.65     20516\n",
      "        Yes       0.38      0.34      0.36     12265\n",
      "\n",
      "avg / total       0.54      0.55      0.54     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[13877  6639]\n",
      " [ 8147  4118]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Linear SVC\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
      "     verbose=0))])\n",
      "train time: 23.579s\n",
      "test time:  7.792s\n",
      "accuracy:   0.569\n",
      "precision:   0.569\n",
      "recall:   0.569\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.63      0.75      0.68     20516\n",
      "        Yes       0.39      0.27      0.32     12265\n",
      "\n",
      "avg / total       0.54      0.57      0.55     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[15302  5214]\n",
      " [ 8913  3352]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: SGDClassifier\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...   penalty='l1', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False))])\n",
      "train time: 19.791s\n",
      "test time:  7.731s\n",
      "accuracy:   0.550\n",
      "precision:   0.550\n",
      "recall:   0.550\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.64      0.66      0.65     20516\n",
      "        Yes       0.39      0.37      0.38     12265\n",
      "\n",
      "avg / total       0.55      0.55      0.55     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[13444  7072]\n",
      " [ 7683  4582]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Nearest Centroid\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...alse,\n",
      "         use_idf=False)), ('clf', NearestCentroid(metric='euclidean', shrink_threshold=None))])\n",
      "train time: 15.217s\n",
      "test time:  7.882s\n",
      "accuracy:   0.542\n",
      "precision:   0.542\n",
      "recall:   0.542\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.67      0.52      0.59     20516\n",
      "        Yes       0.42      0.58      0.49     12265\n",
      "\n",
      "avg / total       0.58      0.54      0.55     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[10657  9859]\n",
      " [ 5160  7105]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Multinomial NB\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...se,\n",
      "         use_idf=False)), ('clf', MultinomialNB(alpha=1e-05, class_prior=None, fit_prior=True))])\n",
      "train time: 15.579s\n",
      "test time:  7.887s\n",
      "accuracy:   0.537\n",
      "precision:   0.537\n",
      "recall:   0.537\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.61      0.73      0.66     20516\n",
      "        Yes       0.32      0.21      0.25     12265\n",
      "\n",
      "avg / total       0.50      0.54      0.51     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[15061  5455]\n",
      " [ 9733  2532]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Bernoulli NB\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ... use_idf=False)), ('clf', BernoulliNB(alpha=1e-05, binarize=0.0, class_prior=None, fit_prior=True))])\n",
      "train time: 14.721s\n",
      "test time:  8.029s\n",
      "accuracy:   0.538\n",
      "precision:   0.538\n",
      "recall:   0.538\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.61      0.74      0.67     20516\n",
      "        Yes       0.31      0.20      0.24     12265\n",
      "\n",
      "avg / total       0.50      0.54      0.51     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[15193  5323]\n",
      " [ 9829  2436]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Linear SVC\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0))])\n",
      "train time: 18.380s\n",
      "test time:  7.807s\n",
      "accuracy:   0.595\n",
      "precision:   0.595\n",
      "recall:   0.595\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.65      0.79      0.71     20516\n",
      "        Yes       0.44      0.28      0.34     12265\n",
      "\n",
      "avg / total       0.57      0.60      0.57     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[16111  4405]\n",
      " [ 8857  3408]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "# results = defaultdict(lambda: defaultdict(list))\n",
    "results = defaultdict(list)\n",
    "\n",
    "X = text_qa_df['text']\n",
    "y = text_qa_df['accepted']\n",
    "\n",
    "X_data, X_val, y_data, y_val = train_test_split(X, y, train_size=0.9, test_size=0.1, random_state=100)\n",
    "\n",
    "X_data = X_data.reset_index(drop=True)\n",
    "print(len(X_data))\n",
    "X_val = X_val.reset_index(drop=True)\n",
    "print(len(X_val))\n",
    "y_data = y_data.reset_index(drop=True)\n",
    "print(len(y_data))\n",
    "y_val = y_val.reset_index(drop=True)\n",
    "print(len(y_val))\n",
    "\n",
    "for train_index, test_index in StratifiedKFold(y_data, 2):#K):\n",
    "    X_train, X_test = X_data[train_index], X_data[test_index]\n",
    "    y_train, y_test = y_data[train_index], y_data[test_index]\n",
    "    \n",
    "    for clf, name in clf_list:\n",
    "        pipeline = Pipeline([\n",
    "            ('vect', CountVectorizer(ngram_range=(1, 2), stop_words='english')),\n",
    "            ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "            ('clf', clf),\n",
    "        ])\n",
    "#         grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "#         benchmark_results = benchmark(grid_search, X_train, X_test, y_train, y_test)\n",
    "        benchmark_results = benchmark(pipeline, X_train, X_test, y_train, y_test, name)\n",
    "        results[name].append(benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: Ridge classifier\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...True,\n",
      "        fit_intercept=True, max_iter=None, normalize=False, solver='lsqr',\n",
      "        tol=0.01))])\n",
      "train time: 16.758s\n",
      "test time:  8.114s\n",
      "accuracy:   0.550\n",
      "precision:   0.550\n",
      "recall:   0.550\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.63      0.67      0.65     20516\n",
      "        Yes       0.39      0.35      0.37     12265\n",
      "\n",
      "avg / total       0.54      0.55      0.54     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[13772  6744]\n",
      " [ 8021  4244]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Perceptron\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ..._iter=50, n_jobs=1, penalty=None, random_state=0, shuffle=True,\n",
      "      verbose=0, warm_start=False))])\n",
      "train time: 16.726s\n",
      "test time:  7.781s\n",
      "accuracy:   0.547\n",
      "precision:   0.547\n",
      "recall:   0.547\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.63      0.68      0.65     20516\n",
      "        Yes       0.38      0.32      0.35     12265\n",
      "\n",
      "avg / total       0.53      0.55      0.54     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[13993  6523]\n",
      " [ 8334  3931]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Passive-aggressive\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...  n_iter=50, n_jobs=1, random_state=None, shuffle=True,\n",
      "              verbose=0, warm_start=False))])\n",
      "train time: 17.103s\n",
      "test time:  7.956s\n",
      "accuracy:   0.543\n",
      "precision:   0.543\n",
      "recall:   0.543\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.63      0.65      0.64     20516\n",
      "        Yes       0.38      0.36      0.37     12265\n",
      "\n",
      "avg / total       0.54      0.54      0.54     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[13347  7169]\n",
      " [ 7823  4442]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Linear SVC\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
      "     verbose=0))])\n",
      "train time: 23.836s\n",
      "test time:  8.110s\n",
      "accuracy:   0.574\n",
      "precision:   0.574\n",
      "recall:   0.574\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.64      0.75      0.69     20516\n",
      "        Yes       0.40      0.28      0.33     12265\n",
      "\n",
      "avg / total       0.55      0.57      0.55     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[15419  5097]\n",
      " [ 8858  3407]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: SGDClassifier\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...   penalty='l1', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False))])\n",
      "train time: 20.165s\n",
      "test time:  7.689s\n",
      "accuracy:   0.548\n",
      "precision:   0.548\n",
      "recall:   0.548\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.63      0.66      0.65     20516\n",
      "        Yes       0.39      0.36      0.37     12265\n",
      "\n",
      "avg / total       0.54      0.55      0.54     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[13521  6995]\n",
      " [ 7821  4444]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Nearest Centroid\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...alse,\n",
      "         use_idf=False)), ('clf', NearestCentroid(metric='euclidean', shrink_threshold=None))])\n",
      "train time: 15.124s\n",
      "test time:  7.836s\n",
      "accuracy:   0.550\n",
      "precision:   0.550\n",
      "recall:   0.550\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.68      0.53      0.60     20516\n",
      "        Yes       0.43      0.58      0.49     12265\n",
      "\n",
      "avg / total       0.58      0.55      0.56     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[10903  9613]\n",
      " [ 5138  7127]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Multinomial NB\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...se,\n",
      "         use_idf=False)), ('clf', MultinomialNB(alpha=1e-05, class_prior=None, fit_prior=True))])\n",
      "train time: 15.931s\n",
      "test time:  7.913s\n",
      "accuracy:   0.537\n",
      "precision:   0.537\n",
      "recall:   0.537\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.61      0.74      0.67     20516\n",
      "        Yes       0.31      0.20      0.24     12265\n",
      "\n",
      "avg / total       0.50      0.54      0.51     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[15190  5326]\n",
      " [ 9866  2399]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Bernoulli NB\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ... use_idf=False)), ('clf', BernoulliNB(alpha=1e-05, binarize=0.0, class_prior=None, fit_prior=True))])\n",
      "train time: 14.929s\n",
      "test time:  7.955s\n",
      "accuracy:   0.537\n",
      "precision:   0.537\n",
      "recall:   0.537\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.61      0.74      0.67     20516\n",
      "        Yes       0.31      0.19      0.24     12265\n",
      "\n",
      "avg / total       0.50      0.54      0.51     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[15255  5261]\n",
      " [ 9905  2360]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Linear SVC\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0))])\n",
      "train time: 19.228s\n",
      "test time:  8.697s\n",
      "accuracy:   0.598\n",
      "precision:   0.598\n",
      "recall:   0.598\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.65      0.79      0.71     20516\n",
      "        Yes       0.44      0.28      0.35     12265\n",
      "\n",
      "avg / total       0.57      0.60      0.57     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[16110  4406]\n",
      " [ 8780  3485]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Ridge classifier\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...True,\n",
      "        fit_intercept=True, max_iter=None, normalize=False, solver='lsqr',\n",
      "        tol=0.01))])\n",
      "train time: 18.268s\n",
      "test time:  7.966s\n",
      "accuracy:   0.545\n",
      "precision:   0.545\n",
      "recall:   0.545\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.63      0.66      0.65     20516\n",
      "        Yes       0.38      0.35      0.36     12265\n",
      "\n",
      "avg / total       0.54      0.55      0.54     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[13621  6895]\n",
      " [ 8010  4255]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Perceptron\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ..._iter=50, n_jobs=1, penalty=None, random_state=0, shuffle=True,\n",
      "      verbose=0, warm_start=False))])\n",
      "train time: 17.986s\n",
      "test time:  7.923s\n",
      "accuracy:   0.548\n",
      "precision:   0.548\n",
      "recall:   0.548\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.63      0.67      0.65     20516\n",
      "        Yes       0.38      0.35      0.37     12265\n",
      "\n",
      "avg / total       0.54      0.55      0.54     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[13694  6822]\n",
      " [ 7998  4267]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Passive-aggressive\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...  n_iter=50, n_jobs=1, random_state=None, shuffle=True,\n",
      "              verbose=0, warm_start=False))])\n",
      "train time: 17.493s\n",
      "test time:  7.732s\n",
      "accuracy:   0.549\n",
      "precision:   0.549\n",
      "recall:   0.549\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.63      0.68      0.65     20516\n",
      "        Yes       0.38      0.34      0.36     12265\n",
      "\n",
      "avg / total       0.54      0.55      0.54     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[13877  6639]\n",
      " [ 8147  4118]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Linear SVC\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
      "     verbose=0))])\n",
      "train time: 23.579s\n",
      "test time:  7.792s\n",
      "accuracy:   0.569\n",
      "precision:   0.569\n",
      "recall:   0.569\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.63      0.75      0.68     20516\n",
      "        Yes       0.39      0.27      0.32     12265\n",
      "\n",
      "avg / total       0.54      0.57      0.55     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[15302  5214]\n",
      " [ 8913  3352]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: SGDClassifier\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...   penalty='l1', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False))])\n",
      "train time: 19.791s\n",
      "test time:  7.731s\n",
      "accuracy:   0.550\n",
      "precision:   0.550\n",
      "recall:   0.550\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.64      0.66      0.65     20516\n",
      "        Yes       0.39      0.37      0.38     12265\n",
      "\n",
      "avg / total       0.55      0.55      0.55     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[13444  7072]\n",
      " [ 7683  4582]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Nearest Centroid\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...alse,\n",
      "         use_idf=False)), ('clf', NearestCentroid(metric='euclidean', shrink_threshold=None))])\n",
      "train time: 15.217s\n",
      "test time:  7.882s\n",
      "accuracy:   0.542\n",
      "precision:   0.542\n",
      "recall:   0.542\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.67      0.52      0.59     20516\n",
      "        Yes       0.42      0.58      0.49     12265\n",
      "\n",
      "avg / total       0.58      0.54      0.55     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[10657  9859]\n",
      " [ 5160  7105]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Multinomial NB\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...se,\n",
      "         use_idf=False)), ('clf', MultinomialNB(alpha=1e-05, class_prior=None, fit_prior=True))])\n",
      "train time: 15.579s\n",
      "test time:  7.887s\n",
      "accuracy:   0.537\n",
      "precision:   0.537\n",
      "recall:   0.537\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.61      0.73      0.66     20516\n",
      "        Yes       0.32      0.21      0.25     12265\n",
      "\n",
      "avg / total       0.50      0.54      0.51     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[15061  5455]\n",
      " [ 9733  2532]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Bernoulli NB\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ... use_idf=False)), ('clf', BernoulliNB(alpha=1e-05, binarize=0.0, class_prior=None, fit_prior=True))])\n",
      "train time: 14.721s\n",
      "test time:  8.029s\n",
      "accuracy:   0.538\n",
      "precision:   0.538\n",
      "recall:   0.538\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.61      0.74      0.67     20516\n",
      "        Yes       0.31      0.20      0.24     12265\n",
      "\n",
      "avg / total       0.50      0.54      0.51     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[15193  5323]\n",
      " [ 9829  2436]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: Linear SVC\n",
      "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        ...max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0))])\n",
      "train time: 18.380s\n",
      "test time:  7.807s\n",
      "accuracy:   0.595\n",
      "precision:   0.595\n",
      "recall:   0.595\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.65      0.79      0.71     20516\n",
      "        Yes       0.44      0.28      0.34     12265\n",
      "\n",
      "avg / total       0.57      0.60      0.57     32781\n",
      "\n",
      "confusion matrix:\n",
      "[[16111  4405]\n",
      " [ 8857  3408]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "# results = defaultdict(lambda: defaultdict(list))\n",
    "results = defaultdict(list)\n",
    "\n",
    "X = text_qa_df['text']\n",
    "y = text_qa_df['accepted']\n",
    "\n",
    "X_data, X_val, y_data, y_val = train_test_split(X, y, train_size=0.9, test_size=0.1, random_state=100)\n",
    "\n",
    "X_data = X_data.reset_index(drop=True)\n",
    "X_val = X_val.reset_index(drop=True)\n",
    "y_data = y_data.reset_index(drop=True)\n",
    "y_val = y_val.reset_index(drop=True)\n",
    "\n",
    "for train_index, test_index in StratifiedKFold(y_data, 2):#K):\n",
    "    X_train, X_test = X_data[train_index], X_data[test_index]\n",
    "    y_train, y_test = y_data[train_index], y_data[test_index]\n",
    "    \n",
    "    for clf, name in clf_list:\n",
    "        pipeline = Pipeline([\n",
    "            ('vect', CountVectorizer(ngram_range=(1, 2), stop_words='english')),\n",
    "            ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "            ('clf', clf),\n",
    "        ])\n",
    "#         grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "#         benchmark_results = benchmark(grid_search, X_train, X_test, y_train, y_test)\n",
    "        benchmark_results = benchmark(pipeline, X_train, X_test, y_train, y_test, name)\n",
    "        results[name].append(benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32781"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    20520\n",
       "True     12261\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Ajax image upload from html file to codeignite...\n",
       "1        How to emulate CPUs in Java? - So I have been ...\n",
       "2        how can i fetch the next auto increment value ...\n",
       "3        Update all column at once mysql - I have follo...\n",
       "4        ArrayList Cannot find variable isJunior - I'm ...\n",
       "5        how to place (push) input values dynamically i...\n",
       "6        Is Javascript constructor function equivalent/...\n",
       "7        Facebook oauth2 login returns (400) bad reques...\n",
       "8        C: Is it legal to subscript an array of incomp...\n",
       "9        Jquery - Convert a link to button in dialog - ...\n",
       "10       C++ copy constructor behaviour - There is a pa...\n",
       "11       How to check which objects collide with b2Cont...\n",
       "12       \"Insert Into\" clause in sybase 15.5 - I am ins...\n",
       "13       Differentiate retina and non-retina display in...\n",
       "14       Where should .sh/bash scripts be placed when u...\n",
       "15       Sail.js requires server restart after running ...\n",
       "16       Setting server timezone to add/subtract time f...\n",
       "17       save custom radio button state ember - I'm usi...\n",
       "18       Get application to wait until Variables are up...\n",
       "19       Artificially firing Page Events in ASP.NET? - ...\n",
       "20       Showing Fatal Error when clicked on system->co...\n",
       "21       Best Techniques to share data between Landscap...\n",
       "22       AJAX won't transfer variable to PHP - I am try...\n",
       "23       TableCell views in UITableView not appearing i...\n",
       "24       QtCreator can't find lastfm library file libla...\n",
       "25       Adding extra parameter to method? - I have bel...\n",
       "26       Want to Shorten this code - I have this Code  ...\n",
       "27       populate combobox from an excel sheet based on...\n",
       "28       Should I use == or === for ... if ($POST[\"var_...\n",
       "29       Google Maps return to origin - I'm using a pre...\n",
       "                               ...                        \n",
       "32855    Reading bytes from URL, and converting binary ...\n",
       "32857    When i am executing the code i am getting a Sy...\n",
       "32858    inform symfony of where repository classes are...\n",
       "32859    PHP + Javascript error: Unexpected token D - I...\n",
       "32860    ItemStateChanged called twice into JComboBox -...\n",
       "32861    How to fetch the non matching rows in Oracle -...\n",
       "32863    Is there a way I can set only one of my groupb...\n",
       "32864    create an xpath expression in java that is to ...\n",
       "32865    Abnormal behavior while using proguard - My Or...\n",
       "32866    Instagram API, /media/recent shows only images...\n",
       "32868    mac os x how to add files to core data databas...\n",
       "32870    How to compile C version of vtd-xml under linu...\n",
       "32872    ejbAccessException when starting JNLP java app...\n",
       "32873    Converting conditional equation from infix to ...\n",
       "32874    AngularJS: convert bound value - I have a boun...\n",
       "32875    Same radiobutton, same position. Why they are ...\n",
       "32877    Returning on completion of a block? - Given th...\n",
       "32879    Why Soft Link is Used in Ubuntu? - This questi...\n",
       "32880    PHP curl is not working on Windows and Apache ...\n",
       "32882    Image map with overlay images not working + JS...\n",
       "32883    Is it considered \"correct\" to use a template f...\n",
       "32884    Removing the contents of an arraylist of custo...\n",
       "32885    What's an alternative to echo grep in parsing ...\n",
       "32887    PHP Error after 2 or more results displayed fr...\n",
       "32888    How to Setup an Image Database on a Server? - ...\n",
       "32889    Make iOS bar button item for iOS 6 to look lik...\n",
       "32890    How do I show a Jpeg photo from LDAP with JSP?...\n",
       "32891    PHP search in array and if exists increment, e...\n",
       "32894    Post the value from js to php - EDTED(\"I thin...\n",
       "32897    Working with Hive Joins - File1: Id fileFile2:...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32589    Unable to access Bower in Laravel app director...\n",
       "32590    How to add winapi to Lua for Windows - I've in...\n",
       "32592    Click on link in iframe then perform jQuery ac...\n",
       "32593    what happened when function return - I know wh...\n",
       "32594    \".errorClass\" of jQuery validate works but the...\n",
       "32599    How to get the full path of a file properly? -...\n",
       "32601    How to print a sublist that contains all of th...\n",
       "32603    Simplest way to store List of Objects in Windo...\n",
       "32605    Use sed/awk to delete a line if the following ...\n",
       "32607    My codes are true , but an error message stop ...\n",
       "32610    FragmentTabHost and custom tabs - I really nee...\n",
       "32612    connection of c# application to server using i...\n",
       "32615    android - Countdown then an action - I want to...\n",
       "32621    AJAX - Sending knockout observables as JSON ob...\n",
       "32623    Missing file from MSDN example for GDI printin...\n",
       "32626    OSX Install Python Distribute - I am trying to...\n",
       "32628    MySQL not recognising datetime index in WHERE ...\n",
       "32631    Loading images from tablet local files with JS...\n",
       "32632    Gulp-sass fails to compile scss file - I'm usi...\n",
       "32633    Versioning etiquette in open source projects? ...\n",
       "32635    How does vim detect and handle mouse scroll wh...\n",
       "32636    Surface mesh generation in MATLAB - I know how...\n",
       "32637    Export a diagram drawn using applet and graphi...\n",
       "32641    Go to current executing statement in Visual St...\n",
       "32645    Match a variable length of number with shell s...\n",
       "32646    Initialize a dynamically added Google Map - I'...\n",
       "32647    What is the best way for IPC in java? - I am u...\n",
       "32648    Handling Security in Asp.net MVC pages with Ac...\n",
       "32651    What is the name of the += method for hash? - ...\n",
       "32653    Getting the dimensions of a newly updated imag...\n",
       "                               ...                        \n",
       "65532    High availability periodic task (cron) on AWS ...\n",
       "65533    Handling JMSExceptions when using JMS, specifi...\n",
       "65534    Zooming and panning of two plotspaces in CoreP...\n",
       "65535    Set variables in JavaScript once function fini...\n",
       "65536    java pass data to JTable's row upon button cli...\n",
       "65537    Building iOS project with Xcode with different...\n",
       "65538    If you call glBufferData after already calling...\n",
       "65539    In magento how to display associated products ...\n",
       "65540    Transform an unicode to a float - With Django,...\n",
       "65541    Java regex replaceAll with boundaries not work...\n",
       "65542    how can i inherit from 2 objects and use both ...\n",
       "65543    String Replacement parameters - (C#)My code se...\n",
       "65544    Pass a function name as parameter in a functio...\n",
       "65545    MySQL special character concat_ws - I want the...\n",
       "65546    Emacs highlight specific words when opening - ...\n",
       "65547    How can I insert data with the correct foreign...\n",
       "65548    Send selected text to festival - How do you se...\n",
       "65549    How can I get the value of a EditTextCell in G...\n",
       "65550    How should I create my json classes to parse t...\n",
       "65551    Data from a select to other page with foreach ...\n",
       "65552    How can i write Simple Mbean to monitor JBOSS ...\n",
       "65553    Preserve constness on assigning an object - Is...\n",
       "65554    Stream Video to website - We have been given a...\n",
       "65555    What is this purpose of this function? - I hav...\n",
       "65556    TestNG specific testsuite not running - I want...\n",
       "65557    How to dynamically show border on a div withou...\n",
       "65558    Running Java application on Ubuntu server - Ho...\n",
       "65559    Batch file to output last line of findstr - I ...\n",
       "65560    How can I sequence this MySQL table correctly ...\n",
       "65561    \"Package not signed correctly\" appearing for s...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "597",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-1f8ff5eaed02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m597\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/antonio/.virtualenvs/lexisnexis/local/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/antonio/.virtualenvs/lexisnexis/local/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m    922\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/antonio/.virtualenvs/lexisnexis/local/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         elif (isinstance(label, tuple) and\n\u001b[0;32m     86\u001b[0m                 isinstance(label[axis], slice)):\n",
      "\u001b[1;32m/home/antonio/.virtualenvs/lexisnexis/local/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/antonio/.virtualenvs/lexisnexis/local/lib/python2.7/site-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   1458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1459\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1460\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1461\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1462\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'integer'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'boolean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_value (pandas/index.c:3113)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_value (pandas/index.c:2844)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3704)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.Int64HashTable.get_item (pandas/hashtable.c:7255)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.Int64HashTable.get_item (pandas/hashtable.c:7193)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 597"
     ]
    }
   ],
   "source": [
    "X_data.ix[597]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.ix[597]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# K = 10\n",
    "# parameters = {\n",
    "#     'vect__max_df': (0.5, 0.75, 1.0),\n",
    "#     'vect__max_features': (None, 1000, 5000, 10000, 50000),\n",
    "#     'vect__ngram_range': ((1, 1), (1, 2), (2, 2), (1, 3), (2, 3), (3, 3)),  # unigrams or bigrams or trigrams\n",
    "#     'vect__stop_words': (None, stopwords.words('english')),\n",
    "#     'tfidf__use_idf': (True, False),\n",
    "#     'tfidf__norm': ('l1', 'l2'),\n",
    "# #     'clf__alpha': (1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6),\n",
    "# #     'clf__penalty': ('l1', 'l2', 'elasticnet'),\n",
    "# #     'clf__n_iter': (10, 50, 80),\n",
    "# #     'clf__loss': ('log', 'modified_huber'),\n",
    "# }\n",
    "# csf_list = [\n",
    "#     (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
    "#     (Perceptron(n_iter=50), \"Perceptron\"),\n",
    "#     (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n",
    "#     (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "#     (RandomForestClassifier(n_estimators=100), \"Random forest\")\n",
    "# ]\n",
    "# results = {}\n",
    "# for clf, name in csf_list:\n",
    "#     pipeline = Pipeline([\n",
    "#         ('vect', CountVectorizer()),\n",
    "#         ('tfidf', TfidfTransformer()),\n",
    "#         ('clf', clf),\n",
    "#     ])\n",
    "#     grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "#     skf = StratifiedKFold(y, K)\n",
    "#     results[name] = cross_val_score(grid_search, X, y, cv=skf, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from the training data using a sparse vectorizer\n",
      "done in 0.398901s at 2.688MB/s\n",
      "n_samples: 5922, n_features: 18088\n",
      "\n",
      "Extracting features from the test data using the same vectorizer\n",
      "done in 0.027828s at 4.383MB/s\n",
      "n_samples: 659, n_features: 18088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split a training set and a test set\n",
    "y_train = train_labels\n",
    "y_test = test_labels\n",
    "\n",
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "t0 = time()\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                             stop_words='english')\n",
    "X_train = vectorizer.fit_transform(data_train.sentence.tolist())\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_train_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "print()\n",
    "\n",
    "print(\"Extracting features from the test data using the same vectorizer\")\n",
    "t0 = time()\n",
    "X_test = vectorizer.transform(data_test.sentence.tolist())\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_test_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 1000 best features by a chi-squared test\n",
      "done in 0.022103s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mapping from integer feature name to original token string\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "opts_select_chi2 = 100\n",
    "\n",
    "print(\"Extracting %d best features by a chi-squared test\" %\n",
    "      opts_select_chi2)\n",
    "t0 = time()\n",
    "ch2 = SelectKBest(chi2, k=opts_select_chi2)\n",
    "X_train = ch2.fit_transform(X_train, y_train)\n",
    "X_test = ch2.transform(X_test)\n",
    "if feature_names:\n",
    "    # keep selected feature names\n",
    "    feature_names = [feature_names[i] for i\n",
    "                     in ch2.get_support(indices=True)]\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "feature_names = np.asarray(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) < 80 else s[:75] + \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
